{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hardhat-detection_with_color.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Xk3VLI26p8"
      },
      "source": [
        "## Yolov5 related imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQArR6V9iDDa"
      },
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCUIPb0ji0B1"
      },
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.google_utils import gdrive_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsMk6KRXjRV5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZalzPhAqi0r2"
      },
      "source": [
        "'''#detecting for a video using given yolov5 detect.py file \n",
        "!python detect.py --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/gdrive/MyDrive/hard-hat-pic'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JemxrgCn3AmC"
      },
      "source": [
        "## Functions required for yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8aE-4sRV3SA"
      },
      "source": [
        "#---------------------------------------\n",
        "import torch.nn as nn\n",
        "#Functions used for yoloV5\n",
        "class Ensemble(nn.ModuleList):\n",
        "    # Ensemble of models\n",
        "    def __init__(self):\n",
        "        super(Ensemble, self).__init__()\n",
        "\n",
        "    def forward(self, x, augment=False):\n",
        "        y = []\n",
        "        for module in self:\n",
        "            y.append(module(x, augment)[0])\n",
        "        # y = torch.stack(y).max(0)[0]  # max ensemble\n",
        "        # y = torch.stack(y).mean(0)  # mean ensemble\n",
        "        y = torch.cat(y, 1)  # nms ensemble\n",
        "        return y, None  # inference, train output\n",
        "\n",
        "def attempt_load(weights, map_location=None):\n",
        "    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\n",
        "    model = Ensemble()\n",
        "    for w in weights if isinstance(weights, list) else [weights]:\n",
        "        attempt_download(w)\n",
        "        ckpt = torch.load(w, map_location=map_location)  # load\n",
        "        model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model\n",
        "\n",
        "    # Compatibility updates\n",
        "    for m in model.modules():\n",
        "        if type(m) in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU]:\n",
        "            m.inplace = True  # pytorch 1.7.0 compatibility\n",
        "        elif type(m) is Conv:\n",
        "            m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility\n",
        "\n",
        "    if len(model) == 1:\n",
        "        return model[-1]  # return model\n",
        "    else:\n",
        "        print('Ensemble created with %s\\n' % weights)\n",
        "        for k in ['names', 'stride']:\n",
        "            setattr(model, k, getattr(model[-1], k))\n",
        "        return model  # return ensemble"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab_t3q743HJS"
      },
      "source": [
        "## Main cell block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn6Ov-I-Wb9s"
      },
      "source": [
        "#imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import cv2 as cv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from models.common import Conv, DWConv\n",
        "from utils.google_utils import attempt_download\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "import os\n",
        "import matplotlib\n",
        "import glob\n",
        "import time\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math \n",
        "\n",
        "#loading torch model\n",
        "device =  \"cpu\"\n",
        "weights = '/content/gdrive/MyDrive/best.pt'\n",
        "model = attempt_load(weights, map_location=device)  \n",
        "cap = cv2.VideoCapture('/content/gdrive/MyDrive/safety_video/Importance of wearing Safety helmets at work.mp4')\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "result = cv2.VideoWriter('/content/gdrive/MyDrive/output_final.mp4', fourcc, 20.0, (frame_width,frame_height))\n",
        "frame_count=0\n",
        "import cv2\n",
        "\n",
        "#main while loop\n",
        "while True:\n",
        "    print(\"Frame count = \",frame_count)\n",
        "    frame_count+=1\n",
        "    ret, img = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if img is not None:\n",
        "      frame = img.copy()\n",
        "      whT = 480\n",
        "      frame = cv2.resize(frame , (whT , whT))\n",
        "      frame = frame[:, :, ::-1].transpose(2, 0, 1)\n",
        "      frame = np.ascontiguousarray(frame)\n",
        "      height,width,layers=img.shape\n",
        "      #---------------forwarding the torch model (yolo v5)--------\n",
        "      frame = frame / 255.0\n",
        "      torch_img = torch.from_numpy(frame).unsqueeze(0).to(device)\n",
        "      with torch.no_grad():\n",
        "          pred = model(torch_img.float() , augment = False)\n",
        "          det_objects = non_max_suppression(pred[0], 0.6, 0.3 , None , False)[0][...,:5].numpy()\n",
        "      print(\"detected objects\",len(det_objects))\n",
        "      objects = [[int((xmin/whT)*width) , int((ymin/whT)*height) , int((xmax/whT)*width) , int((ymax/whT)*height) , score]  for xmin , ymin , xmax , ymax , score in det_objects ]\n",
        "      objects = [[int(xmin) , int(ymin) , int(xmax) , int(ymax) , score]  for xmin , ymin , xmax , ymax , score in objects]\n",
        "      min_dist = np.inf\n",
        "      obj = 0\n",
        "\n",
        "      #-----------------\n",
        "      if len(objects) == 0:\n",
        "          #if no objects were detected\n",
        "          print(\"No objects found in frame!\")\n",
        "          k = cv2.waitKey(33)\n",
        "          result.write(img)\n",
        "          #cv2_imshow(img)\n",
        "          if k==27:    # Esc key to stop\n",
        "              cv2.destroyAllWindows()\n",
        "              break\n",
        "          elif k==-1:  # normally -1 returned,so don't print it\n",
        "              continue\n",
        "      else:\n",
        "          #if atleast 1 obbject is detected\n",
        "          limit_objects = np.array(objects)\n",
        "          for obj in limit_objects:\n",
        "              xmin  , ymin , xmax , ymax , score = obj\n",
        "              if xmin < 0 or ymin < 0 or xmax < 0 or ymax < 0:\n",
        "                  continue\n",
        "              xmin , ymin , xmax , ymax  = int(xmin) , int(ymin) , int(xmax) , int(ymax)\n",
        "              img_object = img[int(ymin):int(ymax), int(xmin):int(xmax)] #cropping detected object\n",
        "              crop_img=img_object[0:math.floor(img_object.shape[0]/3),0:math.floor(img_object.shape[1])] #getting top 1/3rd region of image ( our region of interest)\n",
        "              crop_centre_y=crop_img.shape[0]//2\n",
        "              crop_centre_x=crop_img.shape[1]//2\n",
        "              crop_centre_coord=(crop_centre_x,crop_centre_y)#centre point of R.O.I \n",
        "              b,g,r=crop_img[crop_centre_y,crop_centre_x] #BGR values of centre point of R.O.I\n",
        "              final_color=[int(b),int(g),int(r)]\n",
        "              img=cv2.rectangle(img , (xmin , ymin) , (xmax , ymax) , final_color , 2) #displaying rectangle with color of hard hat\n",
        "              result.write(img)\n",
        "              \n",
        "result.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}